{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open('text_saving/cases.json') as user_file:\n",
    "    \n",
    "    for line in user_file:\n",
    "        results.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'''\n",
    "’s|’t|’re|’ve|’m|’ll|’d| ?\\p{L}+| ?\\p{N}+|\\s+”\n",
    "''')\n",
    "# def get_words(string):\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From',\n",
       " ' court',\n",
       " ' and',\n",
       " ' program',\n",
       " ' offices',\n",
       " ' in',\n",
       " ' the',\n",
       " ' Bronx',\n",
       " ' Brooklyn',\n",
       " ' and',\n",
       " ' Manhattan',\n",
       " ' CASES',\n",
       " ' provides',\n",
       " ' community',\n",
       " 'based',\n",
       " ' alternatives',\n",
       " ' to',\n",
       " ' jail',\n",
       " ' and',\n",
       " ' prison',\n",
       " ' These',\n",
       " ' programs',\n",
       " ' address']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall( pattern, results[0]['Snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set()\n",
    "with open('stop_words.txt', 'r') as stop_words_file:\n",
    "    for line in stop_words_file:\n",
    "        stop_words.add(line.strip())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "pattern = re.compile(r'''\n",
    "’s|’t|’re|’ve|’m|’ll|’d| ?\\p{L}+| ?\\p{N}+”\n",
    "''')\n",
    "\n",
    "def extract_words(result_list):\n",
    "    word_lists = []\n",
    "    vocab = set()\n",
    "    for result in result_list:\n",
    "        title = result.get('Title', '')\n",
    "        snippet = result.get('Snippet', '')\n",
    "        title_words = re.findall(pattern, title.lower())\n",
    "        title_words = [word.strip() for word in title_words if word.strip() not in stop_words]\n",
    "        snippet_words = re.findall(pattern, snippet.lower())\n",
    "        snippet_words = [word.strip() for word in snippet_words if word.strip() not in stop_words]\n",
    "        vocab.update(title_words + snippet_words)\n",
    "        word_lists.append({'title': title_words, 'snippet': snippet_words})\n",
    "    return word_lists, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl, vocab = extract_words(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ['cases'],\n",
       " 'snippet': ['court',\n",
       "  'program',\n",
       "  'offices',\n",
       "  'bronx',\n",
       "  'brooklyn',\n",
       "  'manhattan',\n",
       "  'cases',\n",
       "  'provides',\n",
       "  'community',\n",
       "  'based',\n",
       "  'alternatives',\n",
       "  'jail',\n",
       "  'prison',\n",
       "  'programs',\n",
       "  'address']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = [0, 0, 0, 0, 1, 1, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_list = {word: set() for word in vocab}\n",
    "\n",
    "for i, document in enumerate(wl):\n",
    "    for word in document['title'] + document['snippet']:\n",
    "        inverse_list[word].add(i+1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = set(range(1, 10+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'thomas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minverse_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthomas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'thomas'"
     ]
    }
   ],
   "source": [
    "inverse_list['thomas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(word, docs_with_word, docs_without_word, feedback):\n",
    "  relevant_docs_with_word = 0\n",
    "  relevant_docs_without_word = 0\n",
    "\n",
    "  total_docs = len(docs_with_word) + len(docs_without_word)\n",
    "  \n",
    "  # import pdb; pdb.set_trace()\n",
    "  for doc in docs_with_word:\n",
    "    relevant_docs_with_word += feedback[doc]\n",
    "  for doc in docs_without_word:\n",
    "    relevant_docs_without_word += feedback[doc]\n",
    "\n",
    "  prob_relevant_with_word = relevant_docs_with_word/len(docs_with_word)\n",
    "  prob_irrelevant_with_word = 1 - prob_relevant_with_word\n",
    "  \n",
    "  prob_relevant_without_word = relevant_docs_without_word/len(docs_without_word)\n",
    "  prob_irrelevant_without_word = 1 - prob_relevant_without_word\n",
    "  # import pdb; pdb.set_trace()\n",
    "  impurity_with_word = 1 - (prob_relevant_with_word**2 + prob_irrelevant_with_word**2)\n",
    "  impurity_without_word = 1 - (prob_relevant_without_word**2 + prob_irrelevant_without_word**2)\n",
    "\n",
    "  return impurity_with_word, impurity_without_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'thomas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gini_impurity(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthomas\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43minverse_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthomas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[1;32m      2\u001b[0m               all_documents \u001b[38;5;241m-\u001b[39m inverse_list[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthomas\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      3\u001b[0m               feedback \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:f \u001b[38;5;28;01mfor\u001b[39;00m k, f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(feedback)}\n\u001b[1;32m      4\u001b[0m               )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'thomas'"
     ]
    }
   ],
   "source": [
    "gini_impurity('thomas', inverse_list['thomas'], \n",
    "              all_documents - inverse_list['thomas'],\n",
    "              feedback = {k+1:f for k, f in enumerate(feedback)}\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_relevant_docs = {}\n",
    "\n",
    "for word, docs in inverse_list.items():\n",
    "    number_of_relevant_docs = 0\n",
    "    for doc in docs:\n",
    "        number_of_relevant_docs += feedback[doc - 1]\n",
    "    percentage_of_relevant_docs[word] = number_of_relevant_docs/len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0.6\n",
    "\n",
    "words_to_search = [word for word in vocab if percentage_of_relevant_docs[word]>k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = {}\n",
    "\n",
    "for word in words_to_search:\n",
    "    gini = gini_impurity(word, inverse_list[word], all_documents - inverse_list[word], feedback = {k+1:f for k, f in enumerate(feedback)})\n",
    "    w1 = len(inverse_list[word])/len(all_documents)\n",
    "    w2 = 1.0 - w1\n",
    "    ranking[word] = ( w1*gini[0] + w2*gini[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking\n",
    "for doc in wl:\n",
    "    for word in doc['title']:\n",
    "        if word in words_to_search:\n",
    "            ranking[word] = ranking[word]*0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'covid': 0.0,\n",
       " 'data': 0.0,\n",
       " 'worldometer': 0.1688888888888889,\n",
       " 'cdc': 0.1688888888888889,\n",
       " 'statistics': 0.1688888888888889,\n",
       " 'coronavirus': 0.1688888888888889,\n",
       " 'tracker': 0.1688888888888889,\n",
       " 'daily': 0.17777777777777778,\n",
       " 'updated': 0.17777777777777778,\n",
       " 'notifiable': 0.17777777777777778,\n",
       " 'number': 0.17777777777777778,\n",
       " 'graphs': 0.17777777777777778,\n",
       " 'historical': 0.17777777777777778,\n",
       " 'nationally': 0.17777777777777778,\n",
       " 'recovered': 0.17777777777777778,\n",
       " 'cumulative': 0.17777777777777778,\n",
       " 'routine': 0.17777777777777778,\n",
       " 'supported': 0.17777777777777778,\n",
       " 'tracking': 0.17777777777777778,\n",
       " 'reporting': 0.17777777777777778,\n",
       " 'deaths': 0.17777777777777778,\n",
       " 'reported': 0.17777777777777778,\n",
       " 'charts': 0.17777777777777778,\n",
       " 'pregnancy': 0.17777777777777778,\n",
       " 'disease': 0.17777777777777778,\n",
       " 'weekly': 0.17777777777777778}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = sorted(words_to_search, key= lambda x: ranking[x])\n",
    "{word: ranking[word] for word in res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
